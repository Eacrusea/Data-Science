{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2 Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "En ML usamos la entropía cruzada como una forma de medir que tan bueno es un modelo de variables discretas a través de comparar la distribución de probabilidad que el modelo produce o predice, vs la distribución de probabilidad real dada por los datos de entrenamiento.\n",
    "\n",
    "Podemos ver el siguiente ejemplo que define la forma en que se calcula la entropía cruzada y nos muestra un caso específico:\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/publishintroductiontodeeplearninginpythonandmatlab1-160502102437/95/introduction-to-deep-learning-in-python-and-matlab-54-638.jpg?cb=1462185644\">\n",
    "\n",
    "En este caso interpretamos así: El problema consiste en un modelo o algoritmo de ML que debe producir un vector de 3 elementos indicando la probabilidad de que ciertos datos X pertenezcan a una de 3 categorías.\n",
    "\n",
    "* El modelo de ML produce un vector que indica que estima un 70% de probabilidad de que se trate de la categoría 0, 20% de probabilidad de que se trate de la categoría 1 y 10% de que se trate de la categoría 2.\n",
    "* Los datos reales nos dicen que se trataba de un caso donde con total certeza se sabe que se trata de la categoría 0\n",
    "* La entropía cruzada(a calcular en el ejercicio) nos indica que tan buena es la estimación del modelo, una EC de 0 es un modelo perfecto(en este caso un modelo que predice 100% de prob para la clase 0)\n",
    "\n",
    "**Nota** \n",
    "* Aun que para calcular la entropía usamos logaritmos en base 2, en ML para calcular la entropía cruzada se usa logaritmo natural ya que con este se cumple el proposito **estimar que tanto se alejan las predicciones del modelo de ML de los datos reales** y es comun]mente mas rápido de calcular en la computadora.\n",
    "* Ya que estamos trabajando con vectores que representan distribuciones de probabilidad , podemos toparnos con lo que se conoce como : **sparse vectors**(vectores donde la mayoría de elementos son 0), esto puede producir problemas ya que le logaritmo de 0 no esta definido, tu solución debe tomar en cuenta esto y evitar que devuelva \"nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35667494393873245"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy(y,y_hat):\n",
    "    for i in range(len(y_hat)):\n",
    "        number = y_hat[i]\n",
    "        if number == 0:\n",
    "            y_hat[i] = 1\n",
    "    \n",
    "    S=-np.dot(y,np.log(y_hat))\n",
    "    return S\n",
    "\n",
    "y  = np.array([1,0,0])\n",
    "y_hat = np.array([0.7,0.2,0.1])\n",
    "\n",
    "cross_entropy(y,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Magnitud de un Vector(norma o módulo)\n",
    " \n",
    "\n",
    "Matemáticamente la magnitud de un vector(también conocida como norma vectorial)  nos indica  el tamaño de este , y nos sirve para tener una noción de la distancia desde un punto de referencia(origen) hasta el punto representado por el vector.\n",
    "\n",
    "\n",
    "## Ejercicio 2\n",
    "Crear una función que reciba como parámetro un vector x y calcule su magnitud o norma(euclidiana o L2) ,luego usarla para evaluar 2 vectores que representan los errores generados por 2 modelos de machine learning y concluir cual de los 2 modelos es mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1622776601683795\n",
      "2.449489742783178\n"
     ]
    }
   ],
   "source": [
    "def magnitud(x):\n",
    "    norm=np.sqrt(np.dot(x,x))\n",
    "    return norm\n",
    "\n",
    "errores_modelo1 = np.array([1,2,1,2])\n",
    "errores_modelo2 = np.array([0,1,1,2])\n",
    "\n",
    "print(magnitud(errores_modelo1))\n",
    "print(magnitud(errores_modelo2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Modelo 2 es mejor ya que la magitud de su error es menor que el del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "Usando la función del ejercicio anterior, crea otra función normalizar(x) que reciba de parámetro un vector x aplique normalización sobre este, el resultado debe ser un nuevo vector del tamaño de x cuya magnitud es igual a 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31622777 0.63245553 0.31622777 0.63245553]\n",
      "[0.         0.40824829 0.40824829 0.81649658]\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def normalizar(x):\n",
    "    normali=x/magnitud(x)\n",
    "    return normali\n",
    "print(normalizar(errores_modelo1))\n",
    "print(normalizar(errores_modelo2))\n",
    "print(magnitud(normalizar(errores_modelo1)))\n",
    "print(magnitud(normalizar(errores_modelo2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producto Punto(escalar,interno,interior) y Ortogonalidad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "### Aplicado en DS\n",
    "\n",
    "Se tiene una red neuronal sencilla(y simplificada) como la de la siguiente imagen:\n",
    "<img src=\"https://www.oreilly.com/library/view/practical-convolutional-neural/9781788392303/assets/246151fb-7893-448d-b9bb-7a87b387a24b.png\">\n",
    "\n",
    "Donde:\n",
    "* INPUT LAYER: un vector X de tamaño = 2 que representa los datos de entrada\n",
    "* HIDDEN_LAYER :capa oculta con 2 neuronas definidas por los vectores:\n",
    "    * HL1 = [0.25,0.37]\n",
    "    * HL2 = [-8,14]\n",
    "* OUTPUT_LAYER = capa de salida definida por el vector [4,9]\n",
    "\n",
    "Crear una funcion `neural_network(X)` para calcular:\n",
    "* Calcule la salida de cada neurona en la capa intermedia aplicada a la capa de entrada.\n",
    "* Use el resultado del paso anterior como entrada para la neurona en la capa de salida\n",
    "\n",
    "Asumiendo que cada neurona identifica la similitud entre su entrada y la caracteística que representa concluir:\n",
    "* Para cada vector de entrada Xi , cual neurona intermedia busca la característica que mas se parece a X.\n",
    "* Cual vector de entrada Xi produce una activación alta(salida alta) en la capa de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la red neuronal sobre los siguientes datos X\n",
    "\n",
    "X1 = np.array([0.50,0.72])\n",
    "X2 = np.array([-4,7])\n",
    "X3 = np.zeros_like(X2)\n",
    "X4 = np.ones_like(X1)\n",
    "X5 = np.random.randn(X1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La neurona intermedia de cada vector es:\n",
      "[0.3914 6.08  ] [  1.59 130.  ] [0. 0.] [0.62 6.  ] [ -0.57116887 -11.75168618]\n",
      "La Neurona de Salida es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56.2856, 1176.36, 0.0, 56.48, -108.0498510936645)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tu codigo aqui:\n",
    "HL1=np.array([0.25,0.37])\n",
    "HL2=np.array([-8,14])\n",
    "OL=np.array([4,9])\n",
    "def NI(X):\n",
    "    ni=np.append(np.dot(X,HL1),np.dot(X,HL2))\n",
    "    return ni\n",
    "print('La neurona intermedia de cada vector es:')\n",
    "print(NI(X1),NI(X2),NI(X3),NI(X4),NI(X5))\n",
    "def neural_network(X):\n",
    "    ns=np.dot(NI(X),OL)\n",
    "    return ns\n",
    "print(\"La Neurona de Salida es:\")\n",
    "neural_network(X1),neural_network(X2),neural_network(X3),neural_network(X4),neural_network(X5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para Cada entrada la neurona intermedia que más se parece es HL2\n",
    "De acuerdo a las salidas el vector X2 es el que produce una activación de salida más alta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 (aplicado en DS)\n",
    "La correlación cruzada es una medida de similitud entre 2 funciones como resultado de \"desplazar\" una sobre la otra, comunmente es usada para encontrar características relevantes en una función desconocida o no controlada.\n",
    "\n",
    "En procesamiento de señales por ejemplo es usada para buscar y/o filtrar en una señal que varia en el tiempo cierta caracaterística de interés. Aveces es llamada también \"sliding dot product\" consiste en aplicar en cada punto de una función F el producto punto con cierta función G(comunmente mas corta) y luego \"deslizar\" G a un nuevo punto de la función, el resultado es una nueva función H que se interpreta como :**cuanto se parece** en cada punto la función F a la característica G. \n",
    "\n",
    "<img src=\"https://i.makeagif.com/media/11-25-2015/LZ9Ufj.gif\"  height=\"250\" width=\"300\">\n",
    "\n",
    "En este ejercicio usamos correlación cruzada para calcular las medias moviles promediando 3 puntos que ya vimos en otro ejemplo:\n",
    "\n",
    "El primer paso es definir la función G que define el \"filtro\" a aplicar, para este caso consiste simplemente en un vector con 3 elementos donde cada elemento corresponde a 1/3, luego debemos aplicar el producto punto sobre cada punto de la función o datos originales(en este ejemplo llamados x) a traves aplicar el producto punto en cada elemento \"corriendolo\" de uno en uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09502784  0.33780525  0.8134208 ] dot  [0.33333333 0.33333333 0.33333333] = 0.35206606609781277\n",
      "[0.33780525 0.8134208  0.97949742] dot  [0.33333333 0.33333333 0.33333333] = 0.7102411543079148\n",
      "[0.8134208  0.97949742 0.93155308] dot  [0.33333333 0.33333333 0.33333333] = 0.9081570991592155\n",
      "[0.97949742 0.93155308 0.69755369] dot  [0.33333333 0.33333333 0.33333333] = 0.8695347312023325\n",
      "[0.93155308 0.69755369 0.33583494] dot  [0.33333333 0.33333333 0.33333333] = 0.6549805707408688\n",
      "[ 0.69755369  0.33583494 -0.052225  ] dot  [0.33333333 0.33333333 0.33333333] = 0.32705454517740146\n",
      "[ 0.33583494 -0.052225   -0.47817386] dot  [0.33333333 0.33333333 0.33333333] = -0.06485463864607963\n",
      "[-0.052225   -0.47817386 -0.85602447] dot  [0.33333333 0.33333333 0.33333333] = -0.4621411085742156\n",
      "[-0.47817386 -0.85602447 -0.99239842] dot  [0.33333333 0.33333333 0.33333333] = -0.775532249656872\n",
      "[-0.85602447 -0.99239842 -0.96543258] dot  [0.33333333 0.33333333 0.33333333] = -0.9379518232010888\n",
      "[-0.99239842 -0.96543258 -0.75353449] dot  [0.33333333 0.33333333 0.33333333] = -0.903788497470786\n",
      "[-0.96543258 -0.75353449 -0.44515348] dot  [0.33333333 0.33333333 0.33333333] = -0.7213735168765332\n",
      "[-0.75353449 -0.44515348 -0.09608719] dot  [0.33333333 0.33333333 0.33333333] = -0.4315917193707883\n"
     ]
    }
   ],
   "source": [
    "ruido = 0.1*np.random.randn(15) #el ruido comunmente se debe a aleatoriedad o captura no exacta de info.\n",
    "x = np.linspace(0,2*np.pi,15) + ruido\n",
    "x = np.sin(x)\n",
    "filtro = np.array([1/3,1/3,1/3])\n",
    "for j in r:\n",
    "    h=np.array([x[j-1],x[j],x[j+1]])\n",
    "    dot_h_filter = np.dot(h, filtro)\n",
    "    print(str(h) + \" dot  \" + str(filtro) + \" = \" + str(dot_h_filter))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operadores logicos en vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "Dado el vector x, usar operadores lógicos sobre vectores y acceso a  elementos usando vectores booleanos , escribir un programa que calcule eun nuevo vector z conteniendo el valor absoluto de el vector x.\n",
    "\n",
    "**Nota** No se puede usar np.abs() ni ciclos\n",
    "\n",
    "**Tip** usar un vector booleano para saber que elementos son negativos y deben ser multiplicados por -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.  1.5 1.  0.5 0.  0.5 1.  1.5 2. ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.linspace(-2,2,9)\n",
    "u,v=np.array([x<0],dtype=int),np.array([x>=0],dtype=int)\n",
    "z=(-u*x)+(v*x)\n",
    "print(z)\n",
    "## tu codigo aqui (~ 4 linea de codigo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Ejercicio 7\n",
    "Implementar la función:\n",
    "$$h(x) = \\begin{cases}0 & x< 0\\\\1 & 0<=x\n",
    "\n",
    "$$h(x) = \\begin{cases}0 & x< 0\\\\1 & 0<=x <=1\\\\0 & x> 1\\end{cases}$$\n",
    "\n",
    "Esta debe funcionar para vectores de cualquier tamaño x:\n",
    "\n",
    "```\n",
    "def h(x):\n",
    "    \n",
    "    ...\n",
    "    \n",
    "```\n",
    "**nota** debe ser implementada sin ciclos o ifs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "def h(x):\n",
    "    u=np.array([x>=0],dtype=int)\n",
    "    v=np.array([x<=1],dtype=int)\n",
    "    z=u*v\n",
    "    return z\n",
    "\n",
    "x = np.array([0.1,-2,0.5,5,0,1])\n",
    "print(h(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para casos donde se requiere comportamiento parecido a este pero con mas condiciones, NumPy provee la función **np.select** , la descripción de esta función casi siempre es mas complicada de lo que debería y dificulta entenderla, vamos a buscar entenderla bajo un ejemplo.\n",
    "\n",
    "Básicamente select se basa en :\n",
    "* una lista de condiciones A\n",
    "* una lista de valores a tomar según estas condiciones B\n",
    "* un valor de  resultado default cuando ninguna de las condiciones en la  lista se cumple.\n",
    "Estas 2 listas deben ser del mismo tamañaño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select y performance\n",
    "\n",
    "Usando select implementar una función k(x) con la siguiente definición:\n",
    "$$k(x) = \\begin{cases}-x & x< 0\\\\x^{3}  &0<=x<1\\\\x^{2}  &1<=x<2\\\\4  &otherwise\\end{cases}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aun que select es muy conveniente y útil , no es la opción mas eficiente esto debido a que evalua todas las condiciones y todos los resultados, en programación en general buscamos escribir los programas de la manera mas eficiente posible y evitar calculos innecesarios, esto se vuelve vital en ciencia de datos cuando procesamos grandes volúmenes de información, por eso NumPy nos provee la alternativa a select llamada **piecewise** que funciona de manera similar .\n",
    "\n",
    "Este funciona similar a select pero en vez de calcular todos los posibles resultados, calcula solo aquellos para los que la condición es True e ignora los False,sintácticamente piecewise requiere que los \"resultados\" sesan calcuados usando una lista de funciones por lo cual todos los resultados deben estar contenidos en una función  y el objeto función ser enviado a piecewise (si la función solo se utiliza una vez para este propósito, se puede usar funciones anónimas o lambda).\n",
    "\n",
    "## Ejercicio 8\n",
    "\n",
    "Investigar piecewise:\n",
    "*  Usarlo para implementar la función anterior de manera eficiente\n",
    "*  Usar piscewise para implementar la función:\n",
    "\n",
    "$$m(x) = \\begin{cases}e^{2x} & x< 0\\\\1  &0<=x<=1\\\\e^{1-x}  &x<=1\\\\\\end{cases}$$\n",
    "\n",
    "\n",
    "Nuevamente, sin utilizar ciclos ni ifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13533528, 1.        , 1.        , 1.        , 0.01831564])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cond_exp(x):\n",
    "    c=np.piecewise(x, [x < 0], [1])\n",
    "    d=np.piecewise(x, [x >= 1], [1])\n",
    "    k=np.piecewise(x, [x >= 0,x<1], [1,1])\n",
    "    m=(np.exp(2*x)*c)+(k-c-d)+(np.exp(1-x)*d)\n",
    "    return m\n",
    "cond_exp(np.array([-1,0,0.5,1,5]))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
